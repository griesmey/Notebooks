{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import os\n",
      "import logging\n",
      "import KaggleWord2VecUtility as util\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from word2vec import Word2Vec, Sent2Vec, LineSentence"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logging.basicConfig(format='%(asctime)s : %(threadName)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
      "logging.info(\"running %s\" % \" \".join(sys.argv))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "input_file = 'original_rt_snippets.txt'\n",
      "model = Word2Vec(LineSentence(os.path.join(os.path.dirname('.'), 'data/stanfordSentimentTreebank', input_file)), size=100, window=5, sg=0, min_count=5, workers=8)\n",
      "model.save(input_file + '.model')\n",
      "model.save_word2vec_format(input_file + '.vec')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sent_file = 'sent.txt'\n",
      "model = Sent2Vec(LineSentence(sent_file), model_file=input_file + '.model')\n",
      "model.save_sent2vec_format(sent_file + '.vec')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "generate training set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train = pd.read_csv(os.path.join(os.path.dirname('.'), 'data', 'labeledTrainData.tsv'), header=0, \\\n",
      "                delimiter=\"\\t\", quoting=3)\n",
      "test = pd.read_csv(os.path.join(os.path.dirname('.'), 'data', 'testData.tsv'), header=0, delimiter='\\t', quoting=3)\n",
      "f = open('all_data.txt', 'w')\n",
      "\n",
      "for i in xrange( 0, len(train[\"review\"])):\n",
      "    f.write('{0}\\n'.format(' '.join(util.KaggleWord2VecUtility.review_to_wordlist(train[\"review\"][i], False))))\n",
      "for i in xrange(0, len(test['review'])):\n",
      "    f.write('{0}\\n'.format(' '.join(util.KaggleWord2VecUtility.review_to_wordlist(test[\"review\"][i], False))))\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = Sent2Vec(LineSentence('all_data.txt'), model_file=input_file + '.model')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.save_sent2vec_format('train_test.vec')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_test = []\n",
      "for i, line in enumerate(open('train_test.vec')):\n",
      "    if i == 0:\n",
      "        continue\n",
      "    train_test.append(map(float, line.split()[1:]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len_train = len(train['review'])\n",
      "    \n",
      "X_deep = train_test[:len_train]\n",
      "X_test_deep = train_test[len_train:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i,_ in enumerate(X):\n",
      "    X[i].extend(X_deep[i])\n",
      "for i,_ in enumerate(X_test):\n",
      "    X_test[i].extend(X_test_deep[i])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr = LogisticRegression(penalty='l2', dual=True, tol=0.0001,\n",
      "                         C=15, fit_intercept=True, intercept_scaling=1.0,\n",
      "                         class_weight=None, random_state=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"20 Fold CV Score: \", np.mean(cross_validation.cross_val_score(lr, X, y, cv=20, scoring='roc_auc'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "20 Fold CV Score:  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.571346048\n"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}